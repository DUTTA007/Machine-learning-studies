{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b7065ea0b8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00138415]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "        train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
